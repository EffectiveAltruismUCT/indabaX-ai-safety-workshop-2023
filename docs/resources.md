---
layout: default
featured_image: "assets/images/UCT.jpeg"
title: "AI Safety Resources"
---

# AI Safety Resources

Welcome to our AI Safety Resources page. Here you will find various resources to deepen your understanding of AI Safety, including newsletters to keep you up-to-date, links to external resources, and information about our Slack workspace.

## Newsletters

Here are some newsletters that we recommend to stay informed about AI Safety:

- **The Centre For AI Safety Newsletter**: This is a short and high quality weekly newsletter covering key events in AI with a particular focus on AI safety. Produced by the CAIS or Centre for AI Safety led by Dan Hendrycks. [Subscribe here](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9uZXdzbGV0dGVyLnNhZmUuYWkvYWNjb3VudCIsInAiOjEzMTI4MzU4NiwicyI6MTQ4MTAwOCwiZiI6dHJ1ZSwidSI6OTI0OTg1NDQsImlhdCI6MTY4Nzg3NjIyOSwiZXhwIjoxNjkwNDY4MjI5LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.s9yvtlfrIXeNcSUBBuHOLCZxxyfLPU5pSXr87IZPpcg).



## External Resources

Here are some places to get started for reading further about AI risks:

- [The first place you should visit](https://aisafety.world/): A wonderful map of the landscape of AI safety resources. 
- [Introduction to AI safety by Rob Miles](https://www.youtube.com/watch?v=pYXy-A4siMw): Rob Miles is a popular youtuber who covers AI safety content. This is his intro to AI safety talk.
- [A collection of introductory resources to AI safety](https://www.lesswrong.com/posts/T98kdFL5bxBWSiE3N/best-introductory-overviews-of-agi-safety): Someone collected a whole bunch of useful introductory resources to AI safety.
- [Ajeya Contra on AI being misaligned by default](https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to): Puts forward an argument for why powerful AI will be misaligned by default.
- [Possible funding opportunities from the Long Term Future Fund](https://funds.effectivealtruism.org/funds/far-future): There are many possible sources of funding for doing AI safety related research but this is one of the best sources of funding.


## Join Our Slack Workspace

We have a vibrant community discussing AI Safety on our Slack workspace. If you're interested in joining, please fill out [this interest form](https://forms.gle/D8Cf2LQR1rMNYkL87), and we'll get back to you as soon as possible.

